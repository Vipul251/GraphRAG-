{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "NEO4J_URL = \"neo4j+s://<INSTANCE-ID>.databases.neo4j.io\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"<INSTANCE-PASSWORD>\"\n",
    "NEO4J_DATABASE = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialiseNeo4j():\n",
    "    cypher_schema = [\n",
    "        \"CREATE CONSTRAINT sectionKey IF NOT EXISTS FOR (c:Section) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT chunkKey IF NOT EXISTS FOR (c:Chunk) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT documentKey IF NOT EXISTS FOR (c:Document) REQUIRE (c.url_hash) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT tableKey IF NOT EXISTS FOR (c:Table) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT elementKey IF NOT EXISTS FOR (c:Element) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CALL db.index.vector.createNodeIndex('chunkVectorIndex', 'Embedding', 'value', 1536, 'COSINE');\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        for cypher in cypher_schema:\n",
    "            session.run(cypher)\n",
    "    driver.close()\n",
    "\n",
    "def ingestDocumentNeo4j(elements, doc_location):\n",
    "\n",
    "    cypher_pool = [\n",
    "        # 0 - Document\n",
    "        \"MERGE (d:Document {url_hash: $doc_url_hash_val}) ON CREATE SET d.url = $doc_url_val, d.last_modified = $doc_last_modified_val RETURN d;\",  \n",
    "        # 1 - Section\n",
    "        \"MERGE (p:Section {key: $element_id_val}) ON CREATE SET p:Element, p.page_idx = $page_idx_val, p.title_hash = $title_hash_val, p.block_idx = $block_idx_val, p.title = $title_val, p.tag = $tag_val RETURN p;\",\n",
    "        # 2 - Link Section with the Document\n",
    "        \"MATCH (d:Document {url_hash: $doc_url_hash_val}) MATCH (s:Section {key: $element_id_val}) MERGE (d)<-[:HAS_DOCUMENT]-(s);\",\n",
    "        # 3 - Link Section with a parent Element\n",
    "        \"MATCH (s1:Section {key: $element_id_val}) MATCH (s2:Element {key: $sec_parent_element_id_val}) MERGE (s2)<-[:UNDER_SECTION]-(s1);\",\n",
    "        # 4 - Chunk\n",
    "        \"MERGE (c:Chunk {key: $element_id_val}) ON CREATE SET c:Element, c.sentences = $sentences_val, c.sentences_hash = $sentences_hash_val, c.block_idx = $block_idx_val, c.page_idx = $page_idx_val, c.tag = $tag_val RETURN c;\",\n",
    "        # 5 - Link Chunk to another element\n",
    "        \"MATCH (c:Chunk {key: $element_id_val}) MATCH (s:Element {key:$chk_parent_element_id_val}) MERGE (s)<-[:HAS_PARENT]-(c);\",\n",
    "        # 6 - Table\n",
    "        \"MERGE (t:Table {key: $element_id_val}) ON CREATE SET t:Element, t.name = $name_val, t.doc_url_hash = $doc_url_hash_val, t.block_idx = $block_idx_val, t.page_idx = $page_idx_val, t.html = $html_val, t.rows = $rows_val RETURN t;\",\n",
    "        # 7 - Link Table to Section\n",
    "        \"MATCH (t:Table {key: $element_id_val}) MATCH (s:Section {key: $tb_parent_element_id_val}) MERGE (s)<-[:HAS_PARENT]-(t);\",\n",
    "        # 8 - Link Table to Document\n",
    "        \"MATCH (t:Table {key: $element_id_val}) MATCH (s:Document {url_hash: $doc_url_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\",\n",
    "        # 9 - Image\n",
    "        \"MERGE (t:Image {key: $element_id_val}) ON CREATE SET t:Element, t.name = $name_val, t.doc_url_hash = $doc_url_hash_val, t.block_idx = $block_idx_val, t.page_idx = $page_idx_val RETURN t;\",\n",
    "        # 10 - Link Image to Document\n",
    "        \"MATCH (t:Image {key: $element_id_val}) MATCH (s:Document {url_hash: $doc_url_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\",\n",
    "        # 11 - Link top Chunk to Document\n",
    "        \"MATCH (t:Chunk {key: $element_id_val}) MATCH (s:Document {url_hash: $doc_url_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        cypher = \"\"\n",
    "\n",
    "        # 1 - Create Document node\n",
    "        doc_url_val = doc_location\n",
    "        doc_url_hash_val = hashlib.md5(doc_url_val.encode(\"utf-8\")).hexdigest()\n",
    "        doc_last_modified_val = elements[0].metadata.last_modified\n",
    "\n",
    "        cypher = cypher_pool[0]\n",
    "        session.run(cypher, doc_url_hash_val=doc_url_hash_val, doc_url_val=doc_url_val, doc_last_modified_val=doc_last_modified_val)\n",
    "\n",
    "        # 2 - Create Section nodes if element.category = 'Title'\n",
    "        \n",
    "        countSection = 0\n",
    "        countChunk = 0\n",
    "        countTable = 0\n",
    "        countImage = 0\n",
    "\n",
    "        # iterate all items in list elements and keep an index i\n",
    "        for i, sec in enumerate(elements) :\n",
    "\n",
    "            tag_val = sec.category\n",
    "            page_idx_val = sec.metadata.page_number\n",
    "            block_idx_val = i\n",
    "            element_id_val = sec.id\n",
    "            text_val = sec.text\n",
    "            text_hash_val = hashlib.md5(text_val.encode(\"utf-8\")).hexdigest()\n",
    "            parent_id_val = str(sec.metadata.parent_id)\n",
    "            \n",
    "            if sec.category == 'Title':\n",
    "                            \n",
    "                # MERGE section node\n",
    "                cypher = cypher_pool[1]\n",
    "                session.run(cypher, page_idx_val=page_idx_val\n",
    "                                    , title_hash_val=text_hash_val\n",
    "                                    , title_val=text_val\n",
    "                                    , tag_val=tag_val\n",
    "                                    , block_idx_val=block_idx_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                        )\n",
    "\n",
    "                # Link Section with a parent section or Document\n",
    "\n",
    "                if parent_id_val == \"None\":    # use Document as parent\n",
    "                    cypher = cypher_pool[2]\n",
    "                    session.run(cypher\n",
    "                                        , doc_url_hash_val=doc_url_hash_val\n",
    "                                        , element_id_val=element_id_val\n",
    "                        )\n",
    "\n",
    "                else:   # use parent section\n",
    "                    cypher = cypher_pool[3]\n",
    "                    session.run(cypher\n",
    "                                        , sec_parent_element_id_val=parent_id_val\n",
    "                                        , doc_url_hash_val=doc_url_hash_val\n",
    "                                        , element_id_val=element_id_val\n",
    "                                )\n",
    "                # **** if sec_parent_val == \"None\":    \n",
    "\n",
    "                countSection += 1\n",
    "                continue\n",
    "            # **** for sec in elements: category = 'Title'\n",
    "\n",
    "        \n",
    "        # ------- Continue within the session block -------\n",
    "        # 3 - Create Chunk nodes from chunks\n",
    "\n",
    "            if sec.category == 'NarrativeText' or sec.category == 'List' or sec.category == 'ListItem' \\\n",
    "                or sec.category == 'UncategorizedText' or sec.category == 'Header':\n",
    "\n",
    "\n",
    "                # MERGE chunk node\n",
    "                cypher = cypher_pool[4]\n",
    "                session.run(cypher, sentences_hash_val=text_hash_val\n",
    "                                    , sentences_val=text_val\n",
    "                                    , block_idx_val=block_idx_val\n",
    "                                    , page_idx_val=page_idx_val\n",
    "                                    , tag_val=tag_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                            )\n",
    "                \n",
    "                # Link chunk with a parent Element. If none, link it to Document\n",
    "                \n",
    "                if not parent_id_val == \"None\":\n",
    "\n",
    "                    cypher = cypher_pool[5]\n",
    "                    session.run(cypher\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , chk_parent_element_id_val=parent_id_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                                )\n",
    "                else:   # link chunk to Document\n",
    "                    cypher = cypher_pool[11]\n",
    "                    session.run(cypher\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                                )                    \n",
    "                    \n",
    "                countChunk += 1\n",
    "                continue\n",
    "            # **** for sec in elements: Chunk\n",
    "\n",
    "            # 4 - Create Table nodes\n",
    "\n",
    "            if sec.category == 'Table':\n",
    "\n",
    "                html_val = sec.metadata.text_as_html\n",
    "                # count <tr> in html\n",
    "                rows_val = len(html_val.split('</tr>'))\n",
    "\n",
    "                # MERGE table node\n",
    "\n",
    "                cypher = cypher_pool[6]\n",
    "                session.run(cypher, block_idx_val=block_idx_val\n",
    "                                , page_idx_val=page_idx_val\n",
    "                                , name_val=text_val\n",
    "                                , html_val=html_val\n",
    "                                , rows_val=rows_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                                , element_id_val=element_id_val\n",
    "                            )\n",
    "                \n",
    "                # Link table with a section\n",
    "                # Table always has a parent section \n",
    "                \n",
    "                if not parent_id_val == \"None\":\n",
    "                    cypher = cypher_pool[7]\n",
    "                    session.run(cypher\n",
    "                                    , tb_parent_element_id_val=parent_id_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                                )\n",
    "\n",
    "                else:   # link table to Document\n",
    "                    cypher = cypher_pool[8]\n",
    "                    session.run(cypher\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , element_id_val=element_id_val\n",
    "                                )\n",
    "                countTable += 1\n",
    "                continue\n",
    "            # **** for sec in elements: category = 'Table'\n",
    "        \n",
    "        \n",
    "        # 5 - Create Image nodes\n",
    "\n",
    "            if sec.category == 'Image':\n",
    "\n",
    "                # MERGE Image node\n",
    "\n",
    "                cypher = cypher_pool[9]\n",
    "                session.run(cypher, block_idx_val=block_idx_val\n",
    "                                , page_idx_val=page_idx_val\n",
    "                                , name_val=text_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                                , element_id_val=element_id_val\n",
    "                            )\n",
    "                \n",
    "                # Link image with a section\n",
    "                # Image always linkes to Document \n",
    "            \n",
    "                cypher = cypher_pool[10]\n",
    "                session.run(cypher\n",
    "                                , image_parent_element_id_val=doc_url_hash_val\n",
    "                                , element_id_val=element_id_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "\n",
    "                countImage += 1\n",
    "                continue\n",
    "            # **** for sec in elements: category = 'Image'\n",
    "        # *** for i, sec in enumerate(elements) :\n",
    "            \n",
    "        print(f'\\'{doc_url_val}\\' Done! Summary: ')\n",
    "        print('#Sections: ' + str(countSection))\n",
    "        print('#Chunks: ' + str(countChunk))\n",
    "        print('#Tables: ' + str(countTable))\n",
    "        print('#Images: ' + str(countImage))\n",
    "\n",
    "    # *** with driver.session() as session:\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "\n",
    "# *** def ingestDocumentNeo4j(elements, doc_location):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create constraints and indexes\n",
    "\n",
    "initialiseNeo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'example-docs/layout-parser-paper.pdf' Done! Summary: \n",
      "#Sections: 17\n",
      "#Chunks: 117\n",
      "#Tables: 2\n",
      "#Images: 6\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.staging.base import convert_to_dict\n",
    "from unstructured.staging.base import elements_to_json\n",
    "\n",
    "\n",
    "doc_location = \"example-docs\"\n",
    "doc_file_name = \"layout-parser-paper.pdf\"\n",
    "doc_url = doc_location + \"/\" + doc_file_name\n",
    "\n",
    "# partition the pdf into elements\n",
    "\n",
    "elements = partition_pdf(filename=doc_location+\"/\"+doc_file_name, \n",
    "                         infer_table_structure=True\n",
    "                         )\n",
    "\n",
    "ingestDocumentNeo4j(elements, doc_url)\n",
    "\n",
    "# DONE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# save the elements as a json file\n",
    "\n",
    "convert_to_dict(elements)\n",
    "\n",
    "filename = doc_location+\"/\"+doc_file_name+\".json\"\n",
    "elements_to_json(elements, filename=filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unstructured",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
